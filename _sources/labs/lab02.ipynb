{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa3e7d5e",
   "metadata": {},
   "source": [
    "# Lab 02: Georefereing Location-based Social Media  \n",
    "In this tutorial, we will learn:\n",
    "- How to extract information (e.g., tweets) from location-based social media (e.g., Twitter)\n",
    "- How to identify locational information (e.g., place name) from text-based data (e.g., tweets, newspapers)\n",
    "- How to refer the identified location to metric-based coordinates on the surface of the earcth \n",
    "\n",
    "Several libraries/packages are needed in this tutorial. Use `pip` or `conda` to install them:\n",
    "- [tweepy](https://pypi.org/project/tweepy/): this is library to access the Tweeter API\n",
    "- [spaCy](https://spacy.io/usage): this is the library to do natural lanuguage processing \n",
    "- [spacy-dbpedia-spotlight](https://pypi.org/project/spacy-dbpedia-spotlight/): a small library that annotate recognized entities from spaCy to DBpedia enities. \n",
    "\n",
    "## Part 1: Extracting (geo)text from Twitter\n",
    "This part explains how to extract text-based unstructured information from the social media Twitter via its API. Similar pipline can be used to extract information from other types of social media/Web services (e.g., Foursquare, Yelp, Flickr, etc.).  \n",
    "\n",
    "Twitter is a useful data source for studying the social impacts of events and activities. In this part, we are going to learn how to collect Twitter data using its API. Specifically, we are going to focus on geotagged Twitter data.\n",
    "\n",
    "First, Twitter requires the users of Twitter API to be authenticated by the system. One simple approach to obtain such authentication is by registering a Twitter account. This is the approach we are going to take in this tutorial. \n",
    "\n",
    "Go to the website of Twitter: https://twitter.com/ , and click “Sign up” at the upper right corner. You can skip this step if you already have a Twitter account.\n",
    "\n",
    "After you have registered/logged in to your Twitter account, we are going to obtain the keys that are necessary to use Twitter API. Go to https://apps.twitter.com/ , and sign in using the Twitter account you have just created\n",
    "(sometimes the browser will automatically sign you in).\n",
    "\n",
    "After you have signed in, click the button “Create New App”. Then fill in the necessary information to create an APP. Note that you might need to record your phone number in your Twitter account in order to do so. If you don't like it, feel free to remove your phone number from your account after you have done your project. \n",
    "\n",
    "Then you will be directed to a page (see example below) asking you for a name of your App. Give it a name that you want. \n",
    "\n",
    "![Get Keys from Twitter Developer](lab2-fig1.png)\n",
    "\n",
    "Click `Get keys`. It will then generated API Key, API Key Secret, and Bearer Token (see below for an example). Make sure you copy and paste them into a safe place (e.g., a text editor). We need these authentications later. \n",
    "\n",
    "![Authentication Example](lab2-fig2.png)\n",
    "\n",
    "Next, we also need to obtain the Access Token and its key. To do so, go to the `Projects & Apps`--> Select your App. Then click `Keys and tokens`, and then click `Generate` on the right of `Access Token ane Secret` (see below). Again, make sure you record them in a safe place. We need them later. Note that if for some reasons, you lose your tokens and secrets, this page is where you regenerate them. \n",
    "\n",
    "![Access Token Example](lab2-fig3.png)\n",
    "\n",
    "Once you have your Twitter app set-up, you are ready to access tweets in Python. Begin by importing the necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77bd844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0dfbfa",
   "metadata": {},
   "source": [
    "To access the Twitter API, you will need four things from your Twitter App page. These keys are located in your Twitter app settings in the Keys and Access Tokens tab.\n",
    "- api key\n",
    "- api key seceret\n",
    "- access token \n",
    "- access token secret \n",
    "\n",
    "Below I put in my authentications. You should use yours! But remember to not share these with anyone else because these values are specific to your App."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef5c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key= '5TX6isrDz92kOC1s7qsTFWq5F'\n",
    "api_key_secret= 'DL4Gw2WLNo2bK538lL5GeNYCtiwlsuYUHOlW8NCSQszK3ac101'\n",
    "access_token= '1582847729486684180-VH5N9AEb2zyyFyLOj5BuD8I9ca0ils'\n",
    "access_token_secret = 'e0cvkxJz9AWvu9dq0Fb48r61vkmIaA1JqLLyhEhms5FGt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd29446",
   "metadata": {},
   "source": [
    "With these authentications, we can next build an API variable in Python that build the connection between this Jupyter program and Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9a4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5fe99",
   "metadata": {},
   "source": [
    "For example, now we can send tweets using your API access. Note that your tweet needs to be 280 characters or less:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2101ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(_api=<tweepy.api.API object at 0x7fe4200e7700>, _json={'created_at': 'Wed Oct 19 22:55:47 +0000 2022', 'id': 1582868138827296768, 'id_str': '1582868138827296768', 'text': \"Hello Twitter, I'm sending the first message via Python to you! I learnt it from GEOGM0068. #DataScience\", 'truncated': False, 'entities': {'hashtags': [{'text': 'DataScience', 'indices': [92, 104]}], 'symbols': [], 'user_mentions': [], 'urls': []}, 'source': '<a href=\"https://ruizhugeographer.com/\" rel=\"nofollow\">GEOGM0068-Zhu</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 1582847729486684180, 'id_str': '1582847729486684180', 'name': 'Richard Chu', 'screen_name': 'GEOGM0068', 'location': '', 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 0, 'friends_count': 1, 'listed_count': 0, 'created_at': 'Wed Oct 19 21:35:04 +0000 2022', 'favourites_count': 0, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 1, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1582847827062972431/-8c67lsJ_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1582847827062972431/-8c67lsJ_normal.png', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, created_at=datetime.datetime(2022, 10, 19, 22, 55, 47, tzinfo=datetime.timezone.utc), id=1582868138827296768, id_str='1582868138827296768', text=\"Hello Twitter, I'm sending the first message via Python to you! I learnt it from GEOGM0068. #DataScience\", truncated=False, entities={'hashtags': [{'text': 'DataScience', 'indices': [92, 104]}], 'symbols': [], 'user_mentions': [], 'urls': []}, source='GEOGM0068-Zhu', source_url='https://ruizhugeographer.com/', in_reply_to_status_id=None, in_reply_to_status_id_str=None, in_reply_to_user_id=None, in_reply_to_user_id_str=None, in_reply_to_screen_name=None, author=User(_api=<tweepy.api.API object at 0x7fe4200e7700>, _json={'id': 1582847729486684180, 'id_str': '1582847729486684180', 'name': 'Richard Chu', 'screen_name': 'GEOGM0068', 'location': '', 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 0, 'friends_count': 1, 'listed_count': 0, 'created_at': 'Wed Oct 19 21:35:04 +0000 2022', 'favourites_count': 0, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 1, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1582847827062972431/-8c67lsJ_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1582847827062972431/-8c67lsJ_normal.png', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=1582847729486684180, id_str='1582847729486684180', name='Richard Chu', screen_name='GEOGM0068', location='', description='', url=None, entities={'description': {'urls': []}}, protected=False, followers_count=0, friends_count=1, listed_count=0, created_at=datetime.datetime(2022, 10, 19, 21, 35, 4, tzinfo=datetime.timezone.utc), favourites_count=0, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=1, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1582847827062972431/-8c67lsJ_normal.png', profile_image_url_https='https://pbs.twimg.com/profile_images/1582847827062972431/-8c67lsJ_normal.png', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=True, default_profile=True, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[]), user=User(_api=<tweepy.api.API object at 0x7fe4200e7700>, _json={'id': 1582847729486684180, 'id_str': '1582847729486684180', 'name': 'Richard Chu', 'screen_name': 'GEOGM0068', 'location': '', 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 0, 'friends_count': 1, 'listed_count': 0, 'created_at': 'Wed Oct 19 21:35:04 +0000 2022', 'favourites_count': 0, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 1, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1582847827062972431/-8c67lsJ_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1582847827062972431/-8c67lsJ_normal.png', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=1582847729486684180, id_str='1582847729486684180', name='Richard Chu', screen_name='GEOGM0068', location='', description='', url=None, entities={'description': {'urls': []}}, protected=False, followers_count=0, friends_count=1, listed_count=0, created_at=datetime.datetime(2022, 10, 19, 21, 35, 4, tzinfo=datetime.timezone.utc), favourites_count=0, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=1, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1582847827062972431/-8c67lsJ_normal.png', profile_image_url_https='https://pbs.twimg.com/profile_images/1582847827062972431/-8c67lsJ_normal.png', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=True, default_profile=True, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[]), geo=None, coordinates=None, place=None, contributors=None, is_quote_status=False, retweet_count=0, favorite_count=0, favorited=False, retweeted=False, lang='en')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post a tweet from Python\n",
    "api.update_status(\"Hello Twitter, I'm sending the first message via Python to you! I learnt it from GEOGM0068. #DataScience\")\n",
    "# Your tweet has been posted!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b77ce4",
   "metadata": {},
   "source": [
    "If you go to your Twitter account and check Profile, you will see the tweet being posted! Congrats for your first post via Python!  \n",
    "\n",
    "Note that if you see errors like \"453 - You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, you’ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve\". It means you need to elevate your access. What you need to do is (1). Go to Products --> Twitter API v2; (2). click the tab \"Elevated\" (or \"Academic Research\" if you need it for your dissertation later); (3). Click `Apply`, then file the form (you can choose No for many of the questions). See screenshot below for (1) and (2):\n",
    "\n",
    "![Elevate your access](lab2-fig4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42219c2e",
   "metadata": {},
   "source": [
    "Next, let's retrieve (search) some tweets that are about `#energycrisis` that are posted currently in English. There are going to be many posts returned. To make it easy to illustrate and to save some request (note you have a limited number of requests via this API), we only request 5 from the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42cc2a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.cursor.ItemIterator at 0x7fe4101d0f10>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_words = \"#energycrisis\"\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_words,\n",
    "              lang=\"en\").items(5)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bbd2f6",
   "metadata": {},
   "source": [
    "Here, you see a  an object that you can iterate (i.e. `ItemIterator`) or loop over to access the data collected. Each item in the iterator has various attributes that you can access to get information about each tweet including:\n",
    "\n",
    "- the text of the tweet\n",
    "- who sent the tweet\n",
    "- the date the tweet was sent\n",
    "\n",
    "and more. The code below loops through the object and save the time of the tweet, the user who posted the tweet, the text of the tweet, as well ast the user location to a pandas `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f67a518c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-19 23:58:43+00:00</td>\n",
       "      <td>wildbluethistle</td>\n",
       "      <td>Lonely inside https://t.co/XFcwiIFhXa #goodmus...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-19 23:58:12+00:00</td>\n",
       "      <td>DrowerR</td>\n",
       "      <td>RT @DaveDavos2: @Bowenchris That will NEVER de...</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-19 23:57:48+00:00</td>\n",
       "      <td>grahamtfn</td>\n",
       "      <td>RT @lucycowan83: We're encouraging voluntary o...</td>\n",
       "      <td>Glasgow, Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-19 23:57:16+00:00</td>\n",
       "      <td>SocEntEdinburgh</td>\n",
       "      <td>RT @socialprintandc: For further details on ho...</td>\n",
       "      <td>Edinburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-19 23:53:03+00:00</td>\n",
       "      <td>lindakillian</td>\n",
       "      <td>RT @LevittFlisser: High electric bill poised t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Time             User  \\\n",
       "0 2022-10-19 23:58:43+00:00  wildbluethistle   \n",
       "1 2022-10-19 23:58:12+00:00          DrowerR   \n",
       "2 2022-10-19 23:57:48+00:00        grahamtfn   \n",
       "3 2022-10-19 23:57:16+00:00  SocEntEdinburgh   \n",
       "4 2022-10-19 23:53:03+00:00     lindakillian   \n",
       "\n",
       "                                               Tweet             Location  \n",
       "0  Lonely inside https://t.co/XFcwiIFhXa #goodmus...                       \n",
       "1  RT @DaveDavos2: @Bowenchris That will NEVER de...  Melbourne, Victoria  \n",
       "2  RT @lucycowan83: We're encouraging voluntary o...    Glasgow, Scotland  \n",
       "3  RT @socialprintandc: For further details on ho...            Edinburgh  \n",
       "4  RT @LevittFlisser: High electric bill poised t...                       "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "columns = ['Time', 'User', 'Tweet', 'Location']\n",
    "\n",
    "data = []\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.created_at, tweet.user.screen_name, tweet.text, tweet.user.location])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae036a70",
   "metadata": {},
   "source": [
    "We can further save the dataframe to a local csv file (structured data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce789416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tweets_example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f0879",
   "metadata": {},
   "source": [
    "Note that there is another way of writing the query to Twitter API, which might be more intuitive to some users. For example, you can replace `tweets = tw.Cursor(api.search_tweets,q=search_words,lang=\"en\").items(5)` to something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba85b7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-20 00:00:59+00:00</td>\n",
       "      <td>WhosFibbing</td>\n",
       "      <td>RT @DaveDavos2: @Bowenchris That will NEVER de...</td>\n",
       "      <td>Everywhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-19 23:59:12+00:00</td>\n",
       "      <td>SocEntEdinburgh</td>\n",
       "      <td>RT @socialprintandc: For further details on ho...</td>\n",
       "      <td>Edinburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-19 23:58:43+00:00</td>\n",
       "      <td>wildbluethistle</td>\n",
       "      <td>Lonely inside https://t.co/XFcwiIFhXa #goodmus...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-19 23:58:12+00:00</td>\n",
       "      <td>DrowerR</td>\n",
       "      <td>RT @DaveDavos2: @Bowenchris That will NEVER de...</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-19 23:57:48+00:00</td>\n",
       "      <td>grahamtfn</td>\n",
       "      <td>RT @lucycowan83: We're encouraging voluntary o...</td>\n",
       "      <td>Glasgow, Scotland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Time             User  \\\n",
       "0 2022-10-20 00:00:59+00:00      WhosFibbing   \n",
       "1 2022-10-19 23:59:12+00:00  SocEntEdinburgh   \n",
       "2 2022-10-19 23:58:43+00:00  wildbluethistle   \n",
       "3 2022-10-19 23:58:12+00:00          DrowerR   \n",
       "4 2022-10-19 23:57:48+00:00        grahamtfn   \n",
       "\n",
       "                                               Tweet             Location  \n",
       "0  RT @DaveDavos2: @Bowenchris That will NEVER de...           Everywhere  \n",
       "1  RT @socialprintandc: For further details on ho...            Edinburgh  \n",
       "2  Lonely inside https://t.co/XFcwiIFhXa #goodmus...                       \n",
       "3  RT @DaveDavos2: @Bowenchris That will NEVER de...  Melbourne, Victoria  \n",
       "4  RT @lucycowan83: We're encouraging voluntary o...    Glasgow, Scotland  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets2 = api.search_tweets(q=search_words,lang=\"en\", count=\"5\")\n",
    "data2 = []\n",
    "for tweet2 in tweets2:\n",
    "    data2.append([tweet2.created_at, tweet2.user.screen_name, tweet2.text, tweet2.user.location])\n",
    "df2 = pd.DataFrame(data2, columns=columns)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7128ff",
   "metadata": {},
   "source": [
    "To learn more about the key function `search_tweets()`, check its webpage [here](https://docs.tweepy.org/en/stable/api.html#tweepy.API.search_tweets). Please try yourself to set up some other parameters to see what you can get. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7115f71c",
   "metadata": {},
   "source": [
    "## Part 2: Basic Natural Language Processing and Geoparsing\n",
    "To extract places (or other categories) from text-based (unstructured) data, we need to do some basic Natural Language Processing (NLP), such as tokenization and Part-of-Speech analysis. All these operations can be done through the library `spaCy`. \n",
    "\n",
    "Ideally, you can use the tweets you got from Part 1 to do the experiment. But since sometimes the tweets you get might be very heterogenous and noisy, here we use a clean example (you can also get it from some long news online) to show how to use `spaCy` in order to make sure all the knowledge points are covered in one example. \n",
    "\n",
    "First make sure you have intsalled and imported `spaCy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86ad3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46366c3",
   "metadata": {},
   "source": [
    "`spaCy` comes with pretrained NLP models that can perform most common NLP tasks, such as tokenization, parts of speech (POS) tagging, named entity recognition (NER), transforming to word vectors etc.\n",
    "\n",
    "If you are dealing with a particular language, you can load the spacy model specific to the language using `spacy.load()` function. For example, we want to load the English version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4987ed28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fe3f00d2fd0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load small english model: https://spacy.io/models\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f42e76",
   "metadata": {},
   "source": [
    "This returns a `Language` object that comes ready with multiple built-in capabilities. \n",
    "\n",
    "Now let's say you have your text data in a string. What can be done to understand the structure of the text?\n",
    "\n",
    "First, call the loaded `nlp` object on the text. It should return a processed `Doc` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e9bc6578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse text through the `nlp` model\n",
    "my_text = \"\"\"The economic situation of the country is on edge , as the stock \n",
    "market crashed causing loss of millions. Citizens who had their main investment \n",
    "in the share-market are facing a great loss. Many companies might lay off \n",
    "thousands of people to reduce labor cost\"\"\"\n",
    "\n",
    "my_doc = nlp(my_text)\n",
    "type(my_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1194813a",
   "metadata": {},
   "source": [
    "Hmmm, it is a `Doc` object. But wait, what exactly is a `Doc` object?\n",
    "\n",
    "It is a sequence of tokens that contains not just the original text but all the results produced by the `spaCy` model after processing the text. Useful information such as the lemma of the text, whether it is a stop word or not, named entities, the word vector of the text and so on are pre-computed and readily stored in the `Doc` object.\n",
    "\n",
    "So first, what is a token? \n",
    "\n",
    "As you have learnt from the lecture. Tokens are individual textual entities that make up the text. Typically a token can be the words, punctuation, spaces, etc. Tokenization is the process of converting a text into smaller sub-texts, based on certain predefined rules. For example, sentences are tokenized to words (and punctuation optionally). And paragraphs into sentences, depending on the context.\n",
    "\n",
    "Each token in `spaCy` has different attributes that tell us a great deal of information.\n",
    "\n",
    "Let’s see the token texts on `my_doc`. The string which the token represents can be accessed through the `token.text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ed147165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "economic\n",
      "situation\n",
      "of\n",
      "the\n",
      "country\n",
      "is\n",
      "on\n",
      "edge\n",
      ",\n",
      "as\n",
      "the\n",
      "stock\n",
      "\n",
      "\n",
      "market\n",
      "crashed\n",
      "causing\n",
      "loss\n",
      "of\n",
      "millions\n",
      ".\n",
      "Citizens\n",
      "who\n",
      "had\n",
      "their\n",
      "main\n",
      "investment\n",
      "\n",
      "\n",
      "in\n",
      "the\n",
      "share\n",
      "-\n",
      "market\n",
      "are\n",
      "facing\n",
      "a\n",
      "great\n",
      "loss\n",
      ".\n",
      "Many\n",
      "companies\n",
      "might\n",
      "lay\n",
      "off\n",
      "\n",
      "\n",
      "thousands\n",
      "of\n",
      "people\n",
      "to\n",
      "reduce\n",
      "labor\n",
      "cost\n"
     ]
    }
   ],
   "source": [
    "# Printing the tokens of a doc\n",
    "for token in my_doc:\n",
    "  print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0f7e42",
   "metadata": {},
   "source": [
    "The above tokens contain punctuation and common words like “a”, ” the”, “was”, etc. These do not add any value to the meaning of your text. They are called stop words. We can clean it up.\n",
    "\n",
    "The type of tokens will allow us to clean those noisy tokens such as stop word, punctuation, and space. First, we show whether a token is stop/punctuation or not, and then we use this information to remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95b397f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The -- True --- False\n",
      "economic -- False --- False\n",
      "situation -- False --- False\n",
      "of -- True --- False\n",
      "the -- True --- False\n",
      "country -- False --- False\n",
      "is -- True --- False\n",
      "on -- True --- False\n",
      "edge -- False --- False\n",
      ", -- False --- True\n",
      "as -- True --- False\n",
      "the -- True --- False\n",
      "stock -- False --- False\n",
      "\n",
      " -- False --- False\n",
      "market -- False --- False\n",
      "crashed -- False --- False\n",
      "causing -- False --- False\n",
      "loss -- False --- False\n",
      "of -- True --- False\n",
      "millions -- False --- False\n",
      ". -- False --- True\n",
      "Citizens -- False --- False\n",
      "who -- True --- False\n",
      "had -- True --- False\n",
      "their -- True --- False\n",
      "main -- False --- False\n",
      "investment -- False --- False\n",
      "\n",
      " -- False --- False\n",
      "in -- True --- False\n",
      "the -- True --- False\n",
      "share -- False --- False\n",
      "- -- False --- True\n",
      "market -- False --- False\n",
      "are -- True --- False\n",
      "facing -- False --- False\n",
      "a -- True --- False\n",
      "great -- False --- False\n",
      "loss -- False --- False\n",
      ". -- False --- True\n",
      "Many -- True --- False\n",
      "companies -- False --- False\n",
      "might -- True --- False\n",
      "lay -- False --- False\n",
      "off -- True --- False\n",
      "\n",
      " -- False --- False\n",
      "thousands -- False --- False\n",
      "of -- True --- False\n",
      "people -- False --- False\n",
      "to -- True --- False\n",
      "reduce -- False --- False\n",
      "labor -- False --- False\n",
      "cost -- False --- False\n"
     ]
    }
   ],
   "source": [
    "# Printing tokens and boolean values stored in different attributes\n",
    "for token in my_doc:\n",
    "  print(token.text,'--',token.is_stop,'---',token.is_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63febdec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "economic\n",
      "situation\n",
      "country\n",
      "edge\n",
      "stock\n",
      "market\n",
      "crashed\n",
      "causing\n",
      "loss\n",
      "millions\n",
      "Citizens\n",
      "main\n",
      "investment\n",
      "share\n",
      "market\n",
      "facing\n",
      "great\n",
      "loss\n",
      "companies\n",
      "lay\n",
      "thousands\n",
      "people\n",
      "reduce\n",
      "labor\n",
      "cost\n"
     ]
    }
   ],
   "source": [
    "# Removing StopWords and punctuations\n",
    "my_doc_cleaned = [token for token in my_doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "\n",
    "for token in my_doc_cleaned:\n",
    "  print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaef2e3",
   "metadata": {},
   "source": [
    "To get the POS tagging of your text, you use code like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6351f73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "economic ----  ADJ\n",
      "situation ----  NOUN\n",
      "country ----  NOUN\n",
      "edge ----  NOUN\n",
      "stock ----  NOUN\n",
      "market ----  NOUN\n",
      "crashed ----  VERB\n",
      "causing ----  VERB\n",
      "loss ----  NOUN\n",
      "millions ----  NOUN\n",
      "Citizens ----  NOUN\n",
      "main ----  ADJ\n",
      "investment ----  NOUN\n",
      "share ----  NOUN\n",
      "market ----  NOUN\n",
      "facing ----  VERB\n",
      "great ----  ADJ\n",
      "loss ----  NOUN\n",
      "companies ----  NOUN\n",
      "lay ----  VERB\n",
      "thousands ----  NOUN\n",
      "people ----  NOUN\n",
      "reduce ----  VERB\n",
      "labor ----  NOUN\n",
      "cost ----  NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in my_doc_cleaned:\n",
    "  print(token.text,'---- ',token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b2f235",
   "metadata": {},
   "source": [
    "You will see each word (token) now is associated with a POS tag, whether it is a Noun, a Adj, a Verb, or so on ... POS often can help us disambiguate the meaning of words (or places in GIR). \n",
    "\n",
    "Btw, if you don't know what \"ADJ\" means, you can use code like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a750656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adjective'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('ADJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be99db6",
   "metadata": {},
   "source": [
    "You can also use `spaCy` to do some Named Entity Recognition (including place name identification or geoparsing). For you instance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5c02821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony Stark ---  PERSON\n",
      "StarkEnterprises ---  ORG\n",
      "Emily Clark ---  PERSON\n",
      "Microsoft ---  ORG\n",
      "Manchester ---  GPE\n",
      "Bible ---  WORK_OF_ART\n",
      "French ---  NORP\n"
     ]
    }
   ],
   "source": [
    "text='Tony Stark owns the company StarkEnterprises . Emily Clark works at Microsoft and lives in Manchester. She loves to read the Bible and learn French'\n",
    "doc=nlp(text)\n",
    "\n",
    "for entity in doc.ents:\n",
    "    print(entity.text,'--- ',entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393b1b3",
   "metadata": {},
   "source": [
    "What is \"GPE\"? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35c3d7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('GPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906bf99",
   "metadata": {},
   "source": [
    "spaCy also provides special visualization for NER through displacy. Using `displacy.render()` function, you can set the `style='ent'` to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "71cca081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tony Stark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " owns the company \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    StarkEnterprises\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " . \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Emily Clark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " works at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and lives in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Manchester\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". She loves to read the \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bible\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " and learn \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    French\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using displacy for visualizing NER\n",
    "from spacy import displacy\n",
    "displacy.render(doc,style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0df84b",
   "metadata": {},
   "source": [
    "So far, you have learnt the basics of retrieving information from social media like Twitter, as well as basic NLP operations and named entity recognition (geoparsing is part of it). I suggest you to play with what you have learnt so far by using new data to experiment these functions, changing the parameters of function, combining these skills with what you have learn in Tutorial 1 (e.g., geopandas), etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8665c",
   "metadata": {},
   "source": [
    "## Part 3: Geocoding the recognized place names \n",
    "`spaCy` helps us recognize different categories of tokens from a text, including place names (with tag `GPE` or `LOC`), but have not refer these place names into geographical locations on the surface of the earth. In this part, we will explore ways of geocoding text-based place names to geographic coordinates. There are several cool libraries/packages there for us to directly use, which we will cover some in this tutorial. But before that, let's develop our own geocoding tool first. We might not use it in the future due to its simplicity, but it will help us understand the fundementals behind those technologies, which we have highlighted in our lectures.  \n",
    "\n",
    "First, let's create a variable storing the text that we want to georeference. The text below is copied from the Physical Geography section from the wikipedia page about the UK. We then use `nlp()` to convert the text into a `nlp` object defined by `spacy`. Having this object, we can then extract place names using the label `LOC` and `GPE`. Here we use a `for-loop` to go through all the tokens and only get those that have the two location-related labels, and then save them all into a list `locations`. Then we transfer such a list into a `panda` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f258d8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK ---  GPE\n",
      "the Lake District ---  LOC\n",
      "Pennines ---  LOC\n",
      "North York Moors ---  GPE\n",
      "Scotland ---  GPE\n",
      "UK ---  GPE\n",
      "Helensburgh ---  GPE\n",
      "Scotland ---  GPE\n",
      "Wales ---  GPE\n",
      "Wales ---  GPE\n",
      "Northern Ireland ---  GPE\n",
      "the Mourne Mountains ---  LOC\n",
      "UK ---  GPE\n",
      "UK ---  GPE\n",
      "the Grampian Mountains ---  LOC\n",
      "Scotland ---  GPE\n",
      "Wales ---  GPE\n",
      "England ---  GPE\n",
      "Northern Ireland ---  GPE\n",
      "Scotland ---  GPE\n"
     ]
    }
   ],
   "source": [
    "UK_physicalGeo = \"The physical geography of the UK varies greatly. England consists of mostly lowland terrain, with upland or mountainous terrain only found north-west of the Tees-Exe line. The upland areas include the Lake District, the Pennines, North York Moors, Exmoor and Dartmoor. The lowland areas are typically traversed by ranges of low hills, frequently composed of chalk, and flat plains. Scotland is the most mountainous country in the UK and its physical geography is distinguished by the Highland Boundary Fault which traverses the Scottish mainland from Helensburgh to Stonehaven. The faultline separates the two distinctively different regions of the Highlands to the north and west, and the Lowlands to the south and east. The Highlands are predominantly mountainous, containing the majority of Scotland's mountainous landscape, while the Lowlands contain flatter land, especially across the Central Lowlands, with upland and mountainous terrain located at the Southern Uplands. Wales is mostly mountainous, though south Wales is less mountainous than north and mid Wales. Northern Ireland consists of mostly hilly landscape and its geography includes the Mourne Mountains as well as Lough Neagh, at 388 square kilometres (150 sq mi), the largest body of water in the UK.[12]The overall geomorphology of the UK was shaped by a combination of forces including tectonics and climate change, in particular glaciation in northern and western areas. The tallest mountain in the UK (and British Isles) is Ben Nevis, in the Grampian Mountains, Scotland. The longest river is the River Severn which flows from Wales into England. The largest lake by surface area is Lough Neagh in Northern Ireland, though Scotland's Loch Ness has the largest volume.\"\n",
    "UK_physicalGeo_doc=nlp(UK_physicalGeo)\n",
    "\n",
    "locations = [] \n",
    "\n",
    "for entity in UK_physicalGeo_doc.ents:\n",
    "    if entity.label_ in ['LOC', 'GPE']:\n",
    "        print(entity.text,'--- ',entity.label_)\n",
    "        locations.append([entity.text, entity.label_])\n",
    "locations_df = pd.DataFrame(locations, columns = ['Place Name', 'Tag'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a19e2",
   "metadata": {},
   "source": [
    "Note that we see many duplicates in the list. What we can do is then to delete those duplicates. `pandas` provides a very easy function for us to do it: `drop_duplicates()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "da799668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place Name</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the Lake District</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pennines</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North York Moors</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scotland</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Helensburgh</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wales</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the Mourne Mountains</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the Grampian Mountains</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>England</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Place Name  Tag\n",
       "0                       UK  GPE\n",
       "1        the Lake District  LOC\n",
       "2                 Pennines  LOC\n",
       "3         North York Moors  GPE\n",
       "4                 Scotland  GPE\n",
       "6              Helensburgh  GPE\n",
       "8                    Wales  GPE\n",
       "10        Northern Ireland  GPE\n",
       "11    the Mourne Mountains  LOC\n",
       "14  the Grampian Mountains  LOC\n",
       "17                 England  GPE"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_df = locations_df.drop_duplicates()\n",
    "locations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ddb197",
   "metadata": {},
   "source": [
    "In Python, there are often many ways to achieve the same goal. To use what we have done so far as an example, you can also use the code below to achieve the same (creating the `locations` list). Try it yourself! \n",
    "\n",
    "`locations.extend([[entity.text, entity.label_] for entity in UK_physicalGeo_doc.ents if entity.label_ in [‘LOC’, 'GPE']]`\n",
    "\n",
    "After recognized these place names, we next want to geocode them. First, we want to see how far we can go without using any external geocoding/geoparsing libraries. \n",
    "\n",
    "As we discussed in the lecture, to do geocoding, we need a gazetteer first. Since the example we are using is mostly about the UK, we can use the [Gazetteer of British Place Names](https://gazetteer.org.uk/purchase). Make sure you downloaded the csv file into your local directory, and remember to replace the directory `../../LabData/GBPN_14062021.csv` below to yours. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e12d541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/5n3zc4sn5hlcg8zzz6ysx21m0000gq/T/ipykernel_3617/3736579507.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  UK_gazetteer_df = pd.read_csv('../../LabData/GBPN_14062021.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBPNID</th>\n",
       "      <th>PlaceName</th>\n",
       "      <th>GridRef</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>HistCounty</th>\n",
       "      <th>Division</th>\n",
       "      <th>AdCounty</th>\n",
       "      <th>District</th>\n",
       "      <th>UniAuth</th>\n",
       "      <th>Police</th>\n",
       "      <th>Region</th>\n",
       "      <th>Alternative_Names</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A' Chill</td>\n",
       "      <td>NG2705</td>\n",
       "      <td>57.057719</td>\n",
       "      <td>-6.500908</td>\n",
       "      <td>Argyllshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Highland</td>\n",
       "      <td>Highlands and Islands</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ab Kettleby</td>\n",
       "      <td>SK7223</td>\n",
       "      <td>52.800049</td>\n",
       "      <td>-0.927993</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>Melton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ab Lench</td>\n",
       "      <td>SP0151</td>\n",
       "      <td>52.163533</td>\n",
       "      <td>-1.980962</td>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>Wychavon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>West Mercia</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Abaty Cwm-hir</td>\n",
       "      <td>SO0571</td>\n",
       "      <td>52.331015</td>\n",
       "      <td>-3.389919</td>\n",
       "      <td>Radnorshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Powys</td>\n",
       "      <td>Dyfed Powys</td>\n",
       "      <td>Wales</td>\n",
       "      <td>Abbey-cwm-hir, Abbeycwmhir</td>\n",
       "      <td>Settlement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Abbey-cwm-hir</td>\n",
       "      <td>SO0571</td>\n",
       "      <td>52.331015</td>\n",
       "      <td>-3.389919</td>\n",
       "      <td>Radnorshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Powys</td>\n",
       "      <td>Dyfed Powys</td>\n",
       "      <td>Wales</td>\n",
       "      <td>Abaty Cwm-hir, Abbeycwmhir</td>\n",
       "      <td>Settlement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GBPNID      PlaceName GridRef        Lat       Lng      HistCounty  \\\n",
       "0       1       A' Chill  NG2705  57.057719 -6.500908     Argyllshire   \n",
       "1       2    Ab Kettleby  SK7223  52.800049 -0.927993  Leicestershire   \n",
       "2       3       Ab Lench  SP0151  52.163533 -1.980962  Worcestershire   \n",
       "3       4  Abaty Cwm-hir  SO0571  52.331015 -3.389919     Radnorshire   \n",
       "4       4  Abbey-cwm-hir  SO0571  52.331015 -3.389919     Radnorshire   \n",
       "\n",
       "  Division        AdCounty  District   UniAuth                 Police  \\\n",
       "0      NaN             NaN       NaN  Highland  Highlands and Islands   \n",
       "1      NaN  Leicestershire    Melton       NaN         Leicestershire   \n",
       "2      NaN  Worcestershire  Wychavon       NaN            West Mercia   \n",
       "3      NaN             NaN       NaN     Powys            Dyfed Powys   \n",
       "4      NaN             NaN       NaN     Powys            Dyfed Powys   \n",
       "\n",
       "     Region           Alternative_Names        Type  \n",
       "0  Scotland                         NaN  Settlement  \n",
       "1   England                         NaN  Settlement  \n",
       "2   England                         NaN  Settlement  \n",
       "3     Wales  Abbey-cwm-hir, Abbeycwmhir  Settlement  \n",
       "4     Wales  Abaty Cwm-hir, Abbeycwmhir  Settlement  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "UK_gazetteer_df = pd.read_csv('../../LabData/GBPN_14062021.csv')\n",
    "UK_gazetteer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494a892",
   "metadata": {},
   "source": [
    "This is obiviously a spatial data set. Then, we want to represent the data as `geopandas`. To do so, we will convert the `Lat` and `Lng` columns into a new column, which is `geometry`. We also need to assign the coordinate reference system to the data. \n",
    "\n",
    "If you started doing so, you will quickly find there might be an error saying something is wrong on the `Lat` column. Don't be panic! After you understand what the error indicates, you can go back to the csv file, where you will find a cell value on `Lat` is `53.20N`. This is not a standard way of representing geographic coordinates. What we can do is to simply remove that row, then finish the transformation from dataframe to geodataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "aee3b677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBPNID</th>\n",
       "      <th>PlaceName</th>\n",
       "      <th>GridRef</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>HistCounty</th>\n",
       "      <th>Division</th>\n",
       "      <th>AdCounty</th>\n",
       "      <th>District</th>\n",
       "      <th>UniAuth</th>\n",
       "      <th>Police</th>\n",
       "      <th>Region</th>\n",
       "      <th>Alternative_Names</th>\n",
       "      <th>Type</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A' Chill</td>\n",
       "      <td>NG2705</td>\n",
       "      <td>57.057719</td>\n",
       "      <td>-6.500908</td>\n",
       "      <td>Argyllshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Highland</td>\n",
       "      <td>Highlands and Islands</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-6.50091 57.05772)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ab Kettleby</td>\n",
       "      <td>SK7223</td>\n",
       "      <td>52.800049</td>\n",
       "      <td>-0.927993</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>Melton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-0.92799 52.80005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ab Lench</td>\n",
       "      <td>SP0151</td>\n",
       "      <td>52.163533</td>\n",
       "      <td>-1.980962</td>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>Wychavon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>West Mercia</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-1.98096 52.16353)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Abaty Cwm-hir</td>\n",
       "      <td>SO0571</td>\n",
       "      <td>52.331015</td>\n",
       "      <td>-3.389919</td>\n",
       "      <td>Radnorshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Powys</td>\n",
       "      <td>Dyfed Powys</td>\n",
       "      <td>Wales</td>\n",
       "      <td>Abbey-cwm-hir, Abbeycwmhir</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-3.38992 52.33102)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Abbey-cwm-hir</td>\n",
       "      <td>SO0571</td>\n",
       "      <td>52.331015</td>\n",
       "      <td>-3.389919</td>\n",
       "      <td>Radnorshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Powys</td>\n",
       "      <td>Dyfed Powys</td>\n",
       "      <td>Wales</td>\n",
       "      <td>Abaty Cwm-hir, Abbeycwmhir</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-3.38992 52.33102)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GBPNID      PlaceName GridRef        Lat       Lng      HistCounty  \\\n",
       "0       1       A' Chill  NG2705  57.057719 -6.500908     Argyllshire   \n",
       "1       2    Ab Kettleby  SK7223  52.800049 -0.927993  Leicestershire   \n",
       "2       3       Ab Lench  SP0151  52.163533 -1.980962  Worcestershire   \n",
       "3       4  Abaty Cwm-hir  SO0571  52.331015 -3.389919     Radnorshire   \n",
       "4       4  Abbey-cwm-hir  SO0571  52.331015 -3.389919     Radnorshire   \n",
       "\n",
       "  Division        AdCounty  District   UniAuth                 Police  \\\n",
       "0      NaN             NaN       NaN  Highland  Highlands and Islands   \n",
       "1      NaN  Leicestershire    Melton       NaN         Leicestershire   \n",
       "2      NaN  Worcestershire  Wychavon       NaN            West Mercia   \n",
       "3      NaN             NaN       NaN     Powys            Dyfed Powys   \n",
       "4      NaN             NaN       NaN     Powys            Dyfed Powys   \n",
       "\n",
       "     Region           Alternative_Names        Type                   geometry  \n",
       "0  Scotland                         NaN  Settlement  POINT (-6.50091 57.05772)  \n",
       "1   England                         NaN  Settlement  POINT (-0.92799 52.80005)  \n",
       "2   England                         NaN  Settlement  POINT (-1.98096 52.16353)  \n",
       "3     Wales  Abbey-cwm-hir, Abbeycwmhir  Settlement  POINT (-3.38992 52.33102)  \n",
       "4     Wales  Abaty Cwm-hir, Abbeycwmhir  Settlement  POINT (-3.38992 52.33102)  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UK_gazetteer_df.drop(UK_gazetteer_df[UK_gazetteer_df['Lat'] == '53.20N '].index, inplace = True)\n",
    "\n",
    "UK_gazetteer_gpd = gpd.GeoDataFrame(\n",
    "   UK_gazetteer_df , geometry=gpd.points_from_xy(UK_gazetteer_df.Lng, UK_gazetteer_df.Lat))\n",
    "UK_gazetteer_gpd.set_crs('epsg:4326')\n",
    "UK_gazetteer_gpd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b312d",
   "metadata": {},
   "source": [
    "Now we have the geoparsed place name list and a gazetteer to extract candidate place names with their coordinates. Let's now do a lookup matching. \n",
    "\n",
    "Guess what? We can use the `merge()` (similar to `join()`) operations we learned in Tutoiral 1 to achieve it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "55838431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place Name</th>\n",
       "      <th>Tag</th>\n",
       "      <th>GBPNID</th>\n",
       "      <th>PlaceName</th>\n",
       "      <th>GridRef</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>HistCounty</th>\n",
       "      <th>Division</th>\n",
       "      <th>AdCounty</th>\n",
       "      <th>District</th>\n",
       "      <th>UniAuth</th>\n",
       "      <th>Police</th>\n",
       "      <th>Region</th>\n",
       "      <th>Alternative_Names</th>\n",
       "      <th>Type</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>GPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the Lake District</td>\n",
       "      <td>LOC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pennines</td>\n",
       "      <td>LOC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North York Moors</td>\n",
       "      <td>GPE</td>\n",
       "      <td>198897.0</td>\n",
       "      <td>North York Moors</td>\n",
       "      <td>SE7295</td>\n",
       "      <td>54.347372</td>\n",
       "      <td>-0.886344</td>\n",
       "      <td>Yorkshire</td>\n",
       "      <td>North Riding</td>\n",
       "      <td>North Yorkshire</td>\n",
       "      <td>Ryedale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Yorkshire</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Downs, Moorland</td>\n",
       "      <td>POINT (-0.88634 54.34737)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scotland</td>\n",
       "      <td>GPE</td>\n",
       "      <td>39523.0</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>SK3822</td>\n",
       "      <td>52.796412</td>\n",
       "      <td>-1.428229</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>North West Leicestershire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-1.42823 52.79641)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scotland</td>\n",
       "      <td>GPE</td>\n",
       "      <td>39524.0</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>SP6798</td>\n",
       "      <td>52.57925</td>\n",
       "      <td>-1.000125</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>Harborough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-1.00012 52.57925)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Scotland</td>\n",
       "      <td>GPE</td>\n",
       "      <td>39525.0</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>SU5669</td>\n",
       "      <td>51.417258</td>\n",
       "      <td>-1.196096</td>\n",
       "      <td>Berkshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>West Berkshire</td>\n",
       "      <td>Thames Valley</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-1.19610 51.41726)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scotland</td>\n",
       "      <td>GPE</td>\n",
       "      <td>39526.0</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>TF0030</td>\n",
       "      <td>52.8604</td>\n",
       "      <td>-0.512500</td>\n",
       "      <td>Lincolnshire</td>\n",
       "      <td>Parts of Kesteven</td>\n",
       "      <td>Lincolnshire</td>\n",
       "      <td>South Kesteven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lincolnshire</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-0.51250 52.86040)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scotland</td>\n",
       "      <td>GPE</td>\n",
       "      <td>294460.0</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>SE2340</td>\n",
       "      <td>53.857797</td>\n",
       "      <td>-1.641983</td>\n",
       "      <td>Yorkshire</td>\n",
       "      <td>West Riding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>West Yorkshire</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-1.64198 53.85780)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Helensburgh</td>\n",
       "      <td>GPE</td>\n",
       "      <td>21050.0</td>\n",
       "      <td>Helensburgh</td>\n",
       "      <td>NS2982</td>\n",
       "      <td>56.003981</td>\n",
       "      <td>-4.733445</td>\n",
       "      <td>Dunbartonshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argyll and Bute</td>\n",
       "      <td>Argyll and West Dunbartonshire</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Baile Eilidh</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-4.73344 56.00398)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wales</td>\n",
       "      <td>GPE</td>\n",
       "      <td>47495.0</td>\n",
       "      <td>Wales</td>\n",
       "      <td>SK4782</td>\n",
       "      <td>53.341077</td>\n",
       "      <td>-1.284149</td>\n",
       "      <td>Yorkshire</td>\n",
       "      <td>West Riding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rotherham</td>\n",
       "      <td>South Yorkshire</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-1.28415 53.34108)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wales</td>\n",
       "      <td>GPE</td>\n",
       "      <td>47496.0</td>\n",
       "      <td>Wales</td>\n",
       "      <td>ST5824</td>\n",
       "      <td>51.02019</td>\n",
       "      <td>-2.590189</td>\n",
       "      <td>Somerset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Somerset</td>\n",
       "      <td>South Somerset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-2.59019 51.02019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wales</td>\n",
       "      <td>GPE</td>\n",
       "      <td>64525.0</td>\n",
       "      <td>Wales</td>\n",
       "      <td>SK4782</td>\n",
       "      <td>53.341105</td>\n",
       "      <td>-1.290959</td>\n",
       "      <td>Yorkshire</td>\n",
       "      <td>West Riding</td>\n",
       "      <td>South Yorkshire</td>\n",
       "      <td>Rotherham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Yorkshire</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Civil Parish</td>\n",
       "      <td>POINT (-1.29096 53.34110)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>GPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the Mourne Mountains</td>\n",
       "      <td>LOC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the Grampian Mountains</td>\n",
       "      <td>LOC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>England</td>\n",
       "      <td>GPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Place Name  Tag    GBPNID         PlaceName GridRef  \\\n",
       "0                       UK  GPE       NaN               NaN     NaN   \n",
       "1        the Lake District  LOC       NaN               NaN     NaN   \n",
       "2                 Pennines  LOC       NaN               NaN     NaN   \n",
       "3         North York Moors  GPE  198897.0  North York Moors  SE7295   \n",
       "4                 Scotland  GPE   39523.0          Scotland  SK3822   \n",
       "5                 Scotland  GPE   39524.0          Scotland  SP6798   \n",
       "6                 Scotland  GPE   39525.0          Scotland  SU5669   \n",
       "7                 Scotland  GPE   39526.0          Scotland  TF0030   \n",
       "8                 Scotland  GPE  294460.0          Scotland  SE2340   \n",
       "9              Helensburgh  GPE   21050.0       Helensburgh  NS2982   \n",
       "10                   Wales  GPE   47495.0             Wales  SK4782   \n",
       "11                   Wales  GPE   47496.0             Wales  ST5824   \n",
       "12                   Wales  GPE   64525.0             Wales  SK4782   \n",
       "13        Northern Ireland  GPE       NaN               NaN     NaN   \n",
       "14    the Mourne Mountains  LOC       NaN               NaN     NaN   \n",
       "15  the Grampian Mountains  LOC       NaN               NaN     NaN   \n",
       "16                 England  GPE       NaN               NaN     NaN   \n",
       "\n",
       "          Lat       Lng      HistCounty           Division         AdCounty  \\\n",
       "0         NaN       NaN             NaN                NaN              NaN   \n",
       "1         NaN       NaN             NaN                NaN              NaN   \n",
       "2         NaN       NaN             NaN                NaN              NaN   \n",
       "3   54.347372 -0.886344       Yorkshire       North Riding  North Yorkshire   \n",
       "4   52.796412 -1.428229  Leicestershire                NaN   Leicestershire   \n",
       "5    52.57925 -1.000125  Leicestershire                NaN   Leicestershire   \n",
       "6   51.417258 -1.196096       Berkshire                NaN              NaN   \n",
       "7     52.8604 -0.512500    Lincolnshire  Parts of Kesteven     Lincolnshire   \n",
       "8   53.857797 -1.641983       Yorkshire        West Riding              NaN   \n",
       "9   56.003981 -4.733445  Dunbartonshire                NaN              NaN   \n",
       "10  53.341077 -1.284149       Yorkshire        West Riding              NaN   \n",
       "11   51.02019 -2.590189        Somerset                NaN         Somerset   \n",
       "12  53.341105 -1.290959       Yorkshire        West Riding  South Yorkshire   \n",
       "13        NaN       NaN             NaN                NaN              NaN   \n",
       "14        NaN       NaN             NaN                NaN              NaN   \n",
       "15        NaN       NaN             NaN                NaN              NaN   \n",
       "16        NaN       NaN             NaN                NaN              NaN   \n",
       "\n",
       "                     District          UniAuth  \\\n",
       "0                         NaN              NaN   \n",
       "1                         NaN              NaN   \n",
       "2                         NaN              NaN   \n",
       "3                     Ryedale              NaN   \n",
       "4   North West Leicestershire              NaN   \n",
       "5                  Harborough              NaN   \n",
       "6                         NaN   West Berkshire   \n",
       "7              South Kesteven              NaN   \n",
       "8                         NaN            Leeds   \n",
       "9                         NaN  Argyll and Bute   \n",
       "10                        NaN        Rotherham   \n",
       "11             South Somerset              NaN   \n",
       "12                  Rotherham              NaN   \n",
       "13                        NaN              NaN   \n",
       "14                        NaN              NaN   \n",
       "15                        NaN              NaN   \n",
       "16                        NaN              NaN   \n",
       "\n",
       "                            Police    Region Alternative_Names  \\\n",
       "0                              NaN       NaN               NaN   \n",
       "1                              NaN       NaN               NaN   \n",
       "2                              NaN       NaN               NaN   \n",
       "3                  North Yorkshire   England               NaN   \n",
       "4                   Leicestershire   England               NaN   \n",
       "5                   Leicestershire   England               NaN   \n",
       "6                    Thames Valley   England               NaN   \n",
       "7                     Lincolnshire   England               NaN   \n",
       "8                   West Yorkshire   England               NaN   \n",
       "9   Argyll and West Dunbartonshire  Scotland      Baile Eilidh   \n",
       "10                 South Yorkshire   England               NaN   \n",
       "11               Avon and Somerset   England               NaN   \n",
       "12                 South Yorkshire   England               NaN   \n",
       "13                             NaN       NaN               NaN   \n",
       "14                             NaN       NaN               NaN   \n",
       "15                             NaN       NaN               NaN   \n",
       "16                             NaN       NaN               NaN   \n",
       "\n",
       "               Type                   geometry  \n",
       "0               NaN                       None  \n",
       "1               NaN                       None  \n",
       "2               NaN                       None  \n",
       "3   Downs, Moorland  POINT (-0.88634 54.34737)  \n",
       "4        Settlement  POINT (-1.42823 52.79641)  \n",
       "5        Settlement  POINT (-1.00012 52.57925)  \n",
       "6        Settlement  POINT (-1.19610 51.41726)  \n",
       "7        Settlement  POINT (-0.51250 52.86040)  \n",
       "8        Settlement  POINT (-1.64198 53.85780)  \n",
       "9        Settlement  POINT (-4.73344 56.00398)  \n",
       "10       Settlement  POINT (-1.28415 53.34108)  \n",
       "11       Settlement  POINT (-2.59019 51.02019)  \n",
       "12     Civil Parish  POINT (-1.29096 53.34110)  \n",
       "13              NaN                       None  \n",
       "14              NaN                       None  \n",
       "15              NaN                       None  \n",
       "16              NaN                       None  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_merged = pd.merge(locations_df, UK_gazetteer_gpd, left_on='Place Name', right_on='PlaceName', how = \"left\")\n",
    "locations_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486fc393",
   "metadata": {},
   "source": [
    "Alright, as you can see, many place names, such as \"North York Moors\" and \"Helensburgh\" are now geocoded. You will also notice some places, like \"Wales\" and \"Scotland\" are matched to multiple coordinates. It is because in our gazetteer, there are multiple records about \"Wales\" and \"Scotland\". Note also that these are not the \"Wales\" and \"Scotland\" you are thinking. If you check the gazetteer by searching for rows that have `Place Name` and \"Wales\" for example (see below), you will find these `Wales` are either \"Settlement\" and \"Civil Parish\" in England. \n",
    "\n",
    "Plus, we also see many place names such as \"UK\", \"the Lake District\", \"Pennines\", etc. do not find a match (their GBPNIDs are all NaN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fb4b720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBPNID</th>\n",
       "      <th>PlaceName</th>\n",
       "      <th>GridRef</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>HistCounty</th>\n",
       "      <th>Division</th>\n",
       "      <th>AdCounty</th>\n",
       "      <th>District</th>\n",
       "      <th>UniAuth</th>\n",
       "      <th>Police</th>\n",
       "      <th>Region</th>\n",
       "      <th>Alternative_Names</th>\n",
       "      <th>Type</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47317</th>\n",
       "      <td>47495</td>\n",
       "      <td>Wales</td>\n",
       "      <td>SK4782</td>\n",
       "      <td>53.341077</td>\n",
       "      <td>-1.284149</td>\n",
       "      <td>Yorkshire</td>\n",
       "      <td>West Riding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rotherham</td>\n",
       "      <td>South Yorkshire</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-1.28415 53.34108)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47318</th>\n",
       "      <td>47496</td>\n",
       "      <td>Wales</td>\n",
       "      <td>ST5824</td>\n",
       "      <td>51.02019</td>\n",
       "      <td>-2.590189</td>\n",
       "      <td>Somerset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Somerset</td>\n",
       "      <td>South Somerset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement</td>\n",
       "      <td>POINT (-2.59019 51.02019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62356</th>\n",
       "      <td>64525</td>\n",
       "      <td>Wales</td>\n",
       "      <td>SK4782</td>\n",
       "      <td>53.341105</td>\n",
       "      <td>-1.290959</td>\n",
       "      <td>Yorkshire</td>\n",
       "      <td>West Riding</td>\n",
       "      <td>South Yorkshire</td>\n",
       "      <td>Rotherham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Yorkshire</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Civil Parish</td>\n",
       "      <td>POINT (-1.29096 53.34110)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GBPNID PlaceName GridRef        Lat       Lng HistCounty     Division  \\\n",
       "47317   47495     Wales  SK4782  53.341077 -1.284149  Yorkshire  West Riding   \n",
       "47318   47496     Wales  ST5824   51.02019 -2.590189   Somerset          NaN   \n",
       "62356   64525     Wales  SK4782  53.341105 -1.290959  Yorkshire  West Riding   \n",
       "\n",
       "              AdCounty        District    UniAuth             Police   Region  \\\n",
       "47317              NaN             NaN  Rotherham    South Yorkshire  England   \n",
       "47318         Somerset  South Somerset        NaN  Avon and Somerset  England   \n",
       "62356  South Yorkshire       Rotherham        NaN    South Yorkshire  England   \n",
       "\n",
       "      Alternative_Names          Type                   geometry  \n",
       "47317               NaN    Settlement  POINT (-1.28415 53.34108)  \n",
       "47318               NaN    Settlement  POINT (-2.59019 51.02019)  \n",
       "62356               NaN  Civil Parish  POINT (-1.29096 53.34110)  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UK_gazetteer_gpd.loc[UK_gazetteer_gpd['PlaceName'] == \"Wales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab4706",
   "metadata": {},
   "source": [
    "All these are due to facts that (1). our imported gazetteer is only about places in England, and (2). our simple model is uncapable to capture the context of the text. Do you have better ideas to improve our simple geocoding tool? \n",
    "\n",
    "Now it is a great time to introduce you some \"fancy\" geocoding/geoparsing libraries. Let's try `spacy_dbpedia_spotlight` next. Make sure you have installed it. Assuming we already have the `nlp` objec from previous steps, or you can create a new one like below, below are the code of using the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e96f1eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('UK',\n",
       " 'DBPEDIA_ENT',\n",
       " 'http://dbpedia.org/resource/United_Kingdom',\n",
       " '0.9999999697674871')"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy_dbpedia_spotlight\n",
    "import spacy\n",
    "nlp = spacy.blank('en')\n",
    "# add the pipeline stage\n",
    "nlp.add_pipe('dbpedia_spotlight')\n",
    "# get the document\n",
    "doc = nlp(UK_physicalGeo)\n",
    "# see the entities\n",
    "entities_dbpedia = [(ent.text, ent.label_, ent.kb_id_, ent._.dbpedia_raw_result['@similarityScore']) for ent in doc.ents]\n",
    "entities_dbpedia[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9250bf1",
   "metadata": {},
   "source": [
    "What the code does is to go through all the tokens in the text and try to find the corresponding entities from DBpedia. The result is a list of tuples. One tuple example is as shown in the box. It includes the text that is parsed, its label (notice how different it is than `spaCy`'s labels), its id in DBpedia (this is very useful as all associated information can be further retrieved using this link. We will cover more about in the future lectures and tutorials), and a score from 0-1 (this is the similarity score of the string matching; the higher it is, the more similar the target text with the candidate). \n",
    "\n",
    "Similar to what we did before, we can then transfer this list into a data frame. Note that since we do not have coordinates explicitly listed here, we can simply use `pandas`'s data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d2bff671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>DBpedia Label</th>\n",
       "      <th>DBpedia URI</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>physical geography</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Physical_geography</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/United_Kingdom</td>\n",
       "      <td>0.9999999697674871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/England</td>\n",
       "      <td>0.9999997958868998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lake District</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Lake_District</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moors</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Moorland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Exmoor</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Exmoor</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dartmoor</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Dartmoor</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chalk</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Chalk</td>\n",
       "      <td>0.999982297417919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scotland</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Scotland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Highland Boundary Fault</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Highland_Boundary_...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Scottish</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Scotland</td>\n",
       "      <td>0.9997720847861457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Helensburgh</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Helensburgh</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stonehaven</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Stonehaven</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>faultline</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Faultline_(musician)</td>\n",
       "      <td>0.9838808091555019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Central Lowlands</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Central_Lowlands</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Southern Uplands</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Southern_Uplands</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wales</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Wales</td>\n",
       "      <td>0.9999999999998863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Northern_Ireland</td>\n",
       "      <td>0.999999996766519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>geography</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Geography</td>\n",
       "      <td>0.9947401620497708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mourne Mountains</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Mourne_Mountains</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lough Neagh</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Lough_Neagh</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>geomorphology</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Geomorphology</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>climate change</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Global_warming</td>\n",
       "      <td>0.9859722723298184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>glaciation</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Glacial_period</td>\n",
       "      <td>0.9861545121455497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>British Isles</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/British_Isles</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Nevis</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/River_Nevis</td>\n",
       "      <td>0.9999978752268652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Grampian Mountains</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Grampian_Mountains</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>River Severn</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/River_Severn</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>lake</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Lake</td>\n",
       "      <td>0.999999999890747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Loch Ness</td>\n",
       "      <td>DBPEDIA_ENT</td>\n",
       "      <td>http://dbpedia.org/resource/Loch_Ness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Text DBpedia Label  \\\n",
       "0        physical geography   DBPEDIA_ENT   \n",
       "1                        UK   DBPEDIA_ENT   \n",
       "2                   England   DBPEDIA_ENT   \n",
       "3             Lake District   DBPEDIA_ENT   \n",
       "4                     Moors   DBPEDIA_ENT   \n",
       "5                    Exmoor   DBPEDIA_ENT   \n",
       "6                  Dartmoor   DBPEDIA_ENT   \n",
       "7                     chalk   DBPEDIA_ENT   \n",
       "8                  Scotland   DBPEDIA_ENT   \n",
       "11  Highland Boundary Fault   DBPEDIA_ENT   \n",
       "12                 Scottish   DBPEDIA_ENT   \n",
       "13              Helensburgh   DBPEDIA_ENT   \n",
       "14               Stonehaven   DBPEDIA_ENT   \n",
       "15                faultline   DBPEDIA_ENT   \n",
       "17         Central Lowlands   DBPEDIA_ENT   \n",
       "18         Southern Uplands   DBPEDIA_ENT   \n",
       "19                    Wales   DBPEDIA_ENT   \n",
       "22         Northern Ireland   DBPEDIA_ENT   \n",
       "23                geography   DBPEDIA_ENT   \n",
       "24         Mourne Mountains   DBPEDIA_ENT   \n",
       "25              Lough Neagh   DBPEDIA_ENT   \n",
       "26            geomorphology   DBPEDIA_ENT   \n",
       "28           climate change   DBPEDIA_ENT   \n",
       "29               glaciation   DBPEDIA_ENT   \n",
       "31            British Isles   DBPEDIA_ENT   \n",
       "32                    Nevis   DBPEDIA_ENT   \n",
       "33       Grampian Mountains   DBPEDIA_ENT   \n",
       "35             River Severn   DBPEDIA_ENT   \n",
       "38                     lake   DBPEDIA_ENT   \n",
       "42                Loch Ness   DBPEDIA_ENT   \n",
       "\n",
       "                                          DBpedia URI    Similarity Score  \n",
       "0      http://dbpedia.org/resource/Physical_geography                 1.0  \n",
       "1          http://dbpedia.org/resource/United_Kingdom  0.9999999697674871  \n",
       "2                 http://dbpedia.org/resource/England  0.9999997958868998  \n",
       "3           http://dbpedia.org/resource/Lake_District                 1.0  \n",
       "4                http://dbpedia.org/resource/Moorland                 1.0  \n",
       "5                  http://dbpedia.org/resource/Exmoor                 1.0  \n",
       "6                http://dbpedia.org/resource/Dartmoor                 1.0  \n",
       "7                   http://dbpedia.org/resource/Chalk   0.999982297417919  \n",
       "8                http://dbpedia.org/resource/Scotland                 1.0  \n",
       "11  http://dbpedia.org/resource/Highland_Boundary_...                 1.0  \n",
       "12               http://dbpedia.org/resource/Scotland  0.9997720847861457  \n",
       "13            http://dbpedia.org/resource/Helensburgh                 1.0  \n",
       "14             http://dbpedia.org/resource/Stonehaven                 1.0  \n",
       "15   http://dbpedia.org/resource/Faultline_(musician)  0.9838808091555019  \n",
       "17       http://dbpedia.org/resource/Central_Lowlands                 1.0  \n",
       "18       http://dbpedia.org/resource/Southern_Uplands                 1.0  \n",
       "19                  http://dbpedia.org/resource/Wales  0.9999999999998863  \n",
       "22       http://dbpedia.org/resource/Northern_Ireland   0.999999996766519  \n",
       "23              http://dbpedia.org/resource/Geography  0.9947401620497708  \n",
       "24       http://dbpedia.org/resource/Mourne_Mountains                 1.0  \n",
       "25            http://dbpedia.org/resource/Lough_Neagh                 1.0  \n",
       "26          http://dbpedia.org/resource/Geomorphology                 1.0  \n",
       "28         http://dbpedia.org/resource/Global_warming  0.9859722723298184  \n",
       "29         http://dbpedia.org/resource/Glacial_period  0.9861545121455497  \n",
       "31          http://dbpedia.org/resource/British_Isles                 1.0  \n",
       "32            http://dbpedia.org/resource/River_Nevis  0.9999978752268652  \n",
       "33     http://dbpedia.org/resource/Grampian_Mountains                 1.0  \n",
       "35           http://dbpedia.org/resource/River_Severn                 1.0  \n",
       "38                   http://dbpedia.org/resource/Lake   0.999999999890747  \n",
       "42              http://dbpedia.org/resource/Loch_Ness                 1.0  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Text', 'DBpedia Label', 'DBpedia URI', 'Similarity Score']\n",
    "\n",
    "UK_physicalGeo_DBpedia = pd.DataFrame(entities_dbpedia, columns=columns)\n",
    "UK_physicalGeo_DBpedia = UK_physicalGeo_DBpedia.drop_duplicates()\n",
    "UK_physicalGeo_DBpedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223edc9c",
   "metadata": {},
   "source": [
    "It seems that the coordinate is not extracted from the tool. But if you use the url, for example [https://dbpedia.org/page/Lake_District](https://dbpedia.org/page/Lake_District), you will see a full information about the place, including its geometry and more! See below for instance:\n",
    "![DBpedia-Point](lab2-fig5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a725909d",
   "metadata": {},
   "source": [
    "Again, even thgough `spacy_dbpedia_spotlight` has its advantages, as you can see there are still flaws in such a tool. For example, many non-spatial entiteis are also detected and coordinates are not explicitly show. Do you have any idea on addressing these issues? (hint: maybe check this library - [pyDBpedia](https://github.com/MatteusT/pyDBpedia) which helps you access the data shown in DBpedia). \n",
    "\n",
    "Now, you can also try to use it on your extracted tweets, or other texts you get from the Internet. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
